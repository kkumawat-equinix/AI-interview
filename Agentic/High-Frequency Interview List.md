# High-Frequency Interview Questions: GenAI, Agentic AI & LLM Engineer

Top 80 essential questions for GenAI Developer, Agentic AI Developer, and LLM/ML Engineer roles.

---

## ⭐ TOP 20 — ABSOLUTE MUST-KNOW (Agentic + GenAI)

These are asked everywhere.

### **1. What is an Agent in GenAI?**
An autonomous LLM-based system that can observe → reason → act → reflect using tools.

### **2. What is the Agent Loop?**
Observe → Plan → Act → Reflect → Memory update.

### **3. What is Tool Calling in LLMs?**
When the model chooses and executes external tools/APIs/functions.

### **4. What is a Planner-Executor-Critic architecture?**
* Planner breaks task
* Executor performs
* Critic evaluates & corrects

### **5. What is RAG? Why is it important?**
Retrieval-Augmented Generation — improves factual accuracy by grounding LLM output in knowledge bases.

### **6. Difference: RAG vs Fine-Tuning**
* RAG → external retrieval
* Fine-tuning → model weight update
  RAG is faster & cheaper.

### **7. What is an Embedding Model?**
A model converting text/images/code → vector representation.

### **8. What causes hallucinations?**
Lack of grounding, ambiguous prompts, no retrieval, over-generalization.

### **9. How do you prevent hallucinations?**
* RAG
* Schema enforcement
* Tool calling
* Critic agent
* Parameter tuning

### **10. What is a Multi-Agent System?**
Multiple coordinated agents each specializing in tasks (research, coding, validation).

### **11. What is a Vector Database?**
Stores embeddings for similarity search (Pinecone, FAISS, Chroma).

### **12. What is Memory in an Agent?**
Long-term or task-level storage of facts, states, and interactions.

### **13. What is Function Calling?**
LLM outputs structured JSON to call backend functions.

### **14. What is a Guardrail?**
Safety rules preventing policy violations and hallucinations.

### **15. What is Prompt Engineering?**
Designing prompts to control LLM behavior and outputs.

### **16. Zero-shot vs Few-shot prompting**
Zero: no examples
Few: 1–5 examples
Used to improve accuracy.

### **17. What is Chain-of-Thought?**
Step-by-step reasoning generated by LLM.

### **18. What is Structured Output Enforcement?**
LLM is forced to output JSON, XML, or a schema.

### **19. What is a Context Window?**
Maximum tokens the model can read + write.

### **20. What is fine-tuning vs LoRA?**
LoRA updates small adapter layers → cheaper and faster fine-tuning.

---

## ⭐ TOP 20 — SYSTEM DESIGN (GENAI + AGENTIC)

These questions determine hiring.

### **21. Design a RAG pipeline**
Answer must include:
* Embeddings
* Vector DB
* Retriever
* Reranker
* LLM generator
* Memory
* Evaluation

### **22. How do you design a coding agent?**
Include:
* Planning
* Code generation
* Execution sandbox
* Test generation
* Critic
* Memory

### **23. How to build an agent that uses APIs?**
Discuss tool schemas + argument validation.

### **24. How do you scale RAG?**
Sharding, caching, ANN search, batching, reranking.

### **25. How do you evaluate an agent system?**
* Task success rate
* Accuracy
* Cost
* Latency
* # of tool calls
* Error rate

### **26. How to add memory to an agent?**
Summaries + embeddings + retrieval rules.

### **27. How do you prevent infinite loops in agents?**
Iteration limits + critic + stop conditions.

### **28. What is an Agent Orchestrator?**
Manages workflows between multiple agents.

### **29. How do you design a safe agent?**
Guardrails, filtering, restricted tools.

### **30. Best practices for tool usage?**
Schema enforcement, validation, fallback.

### **31. Why is JSON schema important?**
Ensures tools are called correctly.

### **32. How to reduce LLM cost?**
Caching, smaller models, cascading LLMs.

### **33. How do you store conversation memory?**
Embedding + vector DB + TTL + recurrent summaries.

### **34. Why retrieval reranking?**
Improves relevance of top-k search.

### **35. What metrics matter in GenAI apps?**
Accuracy, citations, latency, cost, coverage.

### **36. Most common RAG failure reasons?**
Bad embeddings, irrelevant chunks, wrong chunking.

### **37. What is chunking?**
Splitting documents into pieces for RAG.

### **38. What is cross-encoder vs bi-encoder?**
Cross-encoder gives higher-quality reranking.

### **39. What is grounding?**
Using external verified data to reduce hallucinations.

### **40. What is an Agent Supervisor?**
Monitors agent decisions and enforces constraints.

---

## ⭐ TOP 20 — GENAI MODELS + LLM THEORY

### **41. What is a Transformer?**
Architecture using attention to process sequences.

### **42. What is Self-Attention?**
Mechanism to weigh importance of tokens.

### **43. What is Positional Encoding?**
Adds position awareness to tokens.

### **44. What is a Decoder-only model?**
Generative LLM (GPT-type).

### **45. What is an Encoder-only model?**
Classification/embedding (BERT-type).

### **46. What is an Encoder–Decoder model?**
Translation, seq2seq.

### **47. What is Tokenization?**
Splitting text into pieces (tokens).

### **48. What is Temperature?**
Controls randomness in output.

### **49. What is Top-p Sampling?**
Nucleus sampling → selects tokens within a probability mass p.

### **50. Why use Transformers over RNNs?**
Parallelism + long-context learning.

---

## ⭐ TOP 20 — PRACTICAL ENGINEERING + DEPLOYMENT

### **51. Best vector DBs to use?**
Pinecone, Weaviate, FAISS, Chroma.

### **52. How to monitor GenAI systems?**
LLM evaluation logs + tool logs + reasoning trace.

### **53. What is latency optimization?**
Cache, batching, async calls, smaller LLM.

### **54. How do you evaluate RAG?**
Precision@K, Recall@K, MRR, grounding score.

### **55. What is prompt caching?**
Storing embeddings of prompts to avoid repeated LLM calls.

### **56. How to store agent events?**
Use event logs + trace database (e.g., LangSmith).

### **57. How do you integrate LLMs with real APIs?**
Function-calling schema.

### **58. What is embedding drift?**
Changes in embeddings after retraining.

### **59. Best practice for chunk sizes?**
200–500 tokens typically works best.

### **60. What is hallucination evaluation?**
Checking if outputs match citation-grounded documents.

### **61. Why multi-step reasoning fails?**
LLM drift + no memory + plan errors.

### **62. How to fix RAG irrelevance issues?**
Better chunking + reranking + larger context.

### **63. What is a knowledge cutoff?**
The date until which the model was trained.

### **64. How do you detect hallucinations automatically?**
Critic model, citations, fact checker.

### **65. How do you store user profile memory?**
Preferences → JSON → embeddings → vector db.

### **66. What is long-context attention?**
Techniques like sliding window, recurrent attention.

### **67. Why LoRA is better than fine-tuning?**
Cheap + fast + fewer hardware requirements.

### **68. What is model quantization?**
Reducing precision (FP32 → INT8) to accelerate inference.

### **69. What is a fast RAG architecture?**
* Hybrid search
* Multi-stage retriever
* Reranker
* Caching
* Small LLM

### **70. What is Multi-Agent Debate?**

Agents argue to converge on the most accurate solution.

### **71. What is a Planning Token Budget?**

How many tokens an agent can spend in planning.

### **72. How do you prevent prompt injection?**

Content filtering + delimiters + no user-controlled tools.

### **73. What is semantic caching?**

Cache similar prompts using embeddings.

### **74. What is a Memory Checkpoint?**

Periodic summary of conversation state.

### **75. What is a Context Stitcher?**

Merging relevant memory chunks into prompt.

### **76. What is Safety Spec?**

Rules that the agent must follow (company policies).

### **77. Why is JSON mode important?**
Reliable tool calling and predictable structure.

### **78. What is a Reranker LLM?**
Small model that scores retrieved documents for relevance.

### **79. Why evaluate agents continuously?**
Agents change behavior as model weights change.

### **80. What kills a GenAI interview fastest?**
Saying: *"Agents just call APIs using LLM prompts."*

You must show:
* Planning
* Memory
* Tool orchestration
* Failure handling
* Safety considerations
